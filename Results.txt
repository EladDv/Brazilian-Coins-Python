Using TensorFlow backend.
Generating classification ready images
Creating dataset for classification
(9623, 100, 100, 3)
Done!

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 98, 98, 64)        1792
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 49, 64)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 49, 49, 64)        36928
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1, 1, 256)         147712
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               32896
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 128)               16512
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 645
=================================================================
Total params: 347,269.0
Trainable params: 347,269.0
Non-trainable params: 0.0
_________________________________________________________________
Epoch 1/50
2017-05-20 17:33:51.227620: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:33:51.227669: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:33:51.227680: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:33:51.227692: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:33:51.227712: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:33:54.129152: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-05-20 17:33:54.129664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-05-20 17:33:54.129696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-05-20 17:33:54.129716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-05-20 17:33:54.129730: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
7680/7698 [============================>.] - ETA: 0s - loss: 1.6426 - categorical_accuracy: 0.3617Epoch 00000: loss improved from inf to 1.64180, saving model to coins-weights-i7698/7698 [==============================] - 17s - loss: 1.6418 - categorical_accuracy: 0.3622
Epoch 2/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.7693 - categorical_accuracy: 0.7292Epoch 00001: loss improved from 1.64180 to 0.76819, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.7682 - categorical_accuracy: 0.7294
Epoch 3/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.4193 - categorical_accuracy: 0.8577Epoch 00002: loss improved from 0.76819 to 0.41927, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.4193 - categorical_accuracy: 0.8578
Epoch 4/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.3720 - categorical_accuracy: 0.8725Epoch 00003: loss improved from 0.41927 to 0.37185, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.3718 - categorical_accuracy: 0.8724
Epoch 5/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.2944 - categorical_accuracy: 0.8911Epoch 00004: loss improved from 0.37185 to 0.29412, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.2941 - categorical_accuracy: 0.8913
Epoch 6/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.2788 - categorical_accuracy: 0.9035Epoch 00005: loss improved from 0.29412 to 0.27886, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.2789 - categorical_accuracy: 0.9035
Epoch 7/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.2150 - categorical_accuracy: 0.9184Epoch 00006: loss improved from 0.27886 to 0.21499, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.2150 - categorical_accuracy: 0.9184
Epoch 8/50
7698/7698 [==============================] - 12s - loss: 0.2228 - categorical_accuracy: 0.9215    Epoch 00007: loss did not improve
Epoch 9/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.1666 - categorical_accuracy: 0.9409Epoch 00008: loss improved from 0.21499 to 0.16753, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.1675 - categorical_accuracy: 0.9408
Epoch 10/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.1477 - categorical_accuracy: 0.9492Epoch 00009: loss improved from 0.16753 to 0.14783, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.1478 - categorical_accuracy: 0.9491
Epoch 11/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.1296 - categorical_accuracy: 0.9551Epoch 00010: loss improved from 0.14783 to 0.12970, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.1297 - categorical_accuracy: 0.9551
Epoch 12/50
7698/7698 [==============================] - 12s - loss: 0.1346 - categorical_accuracy: 0.9530    Epoch 00011: loss did not improve
Epoch 13/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.1044 - categorical_accuracy: 0.9660Epoch 00012: loss improved from 0.12970 to 0.10424, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.1042 - categorical_accuracy: 0.9661
Epoch 14/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0744 - categorical_accuracy: 0.9758Epoch 00013: loss improved from 0.10424 to 0.07426, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0743 - categorical_accuracy: 0.9758
Epoch 15/50
7698/7698 [==============================] - 12s - loss: 0.0833 - categorical_accuracy: 0.9714    Epoch 00014: loss did not improve
Epoch 16/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0634 - categorical_accuracy: 0.9794Epoch 00015: loss improved from 0.07426 to 0.06410, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0641 - categorical_accuracy: 0.9792
Epoch 17/50
7698/7698 [==============================] - 12s - loss: 0.0975 - categorical_accuracy: 0.9682    Epoch 00016: loss did not improve
Epoch 18/50
7698/7698 [==============================] - 12s - loss: 0.0683 - categorical_accuracy: 0.9770    Epoch 00017: loss did not improve
Epoch 19/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0508 - categorical_accuracy: 0.9837Epoch 00018: loss improved from 0.06410 to 0.05070, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0507 - categorical_accuracy: 0.9838
Epoch 20/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0430 - categorical_accuracy: 0.9866Epoch 00019: loss improved from 0.05070 to 0.04291, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0429 - categorical_accuracy: 0.9866
Epoch 21/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0302 - categorical_accuracy: 0.9902Epoch 00020: loss improved from 0.04291 to 0.03010, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0301 - categorical_accuracy: 0.9903
Epoch 22/50
7698/7698 [==============================] - 12s - loss: 0.0370 - categorical_accuracy: 0.9873    Epoch 00021: loss did not improve
Epoch 23/50
7698/7698 [==============================] - 12s - loss: 0.0499 - categorical_accuracy: 0.9851    Epoch 00022: loss did not improve
Epoch 24/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0254 - categorical_accuracy: 0.9921Epoch 00023: loss improved from 0.03010 to 0.02539, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0254 - categorical_accuracy: 0.9921
Epoch 25/50
7680/7698 [============================>.] - ETA: 0s - loss: 0.0152 - categorical_accuracy: 0.9965Epoch 00024: loss improved from 0.02539 to 0.01521, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0152 - categorical_accuracy: 0.9965
Epoch 26/50
 256/7698 [..............................] - ETA: 11s - loss: 0.0100 - categorical_accuracy: 0.9961

Traceback (most recent call last):
KeyboardInterrupt

(NN) ubuntu@ip-172-31-34-77:~$ python3 CoinRecognition4.py
Using TensorFlow backend.
Generating classification ready images
Creating dataset for classification
(9623, 100, 100, 3)
Done!

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 98, 98, 64)        1792
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 49, 64)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 49, 49, 64)        36928
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1, 1, 256)         147712
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               32896
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 128)               16512
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 645
=================================================================
Total params: 347,269.0
Trainable params: 347,269.0
Non-trainable params: 0.0
_________________________________________________________________
2017-05-20 17:40:26.856869: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:40:26.856924: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:40:26.856930: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:40:26.856943: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:40:26.856958: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:40:29.904582: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-05-20 17:40:29.905102: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-05-20 17:40:29.905128: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-05-20 17:40:29.905138: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-05-20 17:40:29.905147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
Epoch 1/1
7680/7698 [============================>.] - ETA: 0s - loss: 0.0542 - categorical_accuracy: 0.9822Epoch 00000: loss improved from inf to 0.05411, saving model to coins-weights-i7698/7698 [==============================] - 13s - loss: 0.0541 - categorical_accuracy: 0.9822
1925/1925 [==============================] - 1s
Accuracy: 98.75%
(NN) ubuntu@ip-172-31-34-77:~$ python3 CoinRecognition4.py
Using TensorFlow backend.
Generating classification ready images
Creating dataset for classification
(9623, 100, 100, 3)
Done!

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 98, 98, 64)        1792
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 49, 64)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 49, 49, 64)        36928
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1, 1, 256)         147712
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               32896
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 128)               16512
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 645
=================================================================
Total params: 347,269.0
Trainable params: 347,269.0
Non-trainable params: 0.0
_________________________________________________________________
2017-05-20 17:41:12.972007: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:41:12.972061: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:41:12.972068: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:41:12.972081: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:41:12.972095: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:41:16.028063: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-05-20 17:41:16.028581: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-05-20 17:41:16.028611: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-05-20 17:41:16.028628: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-05-20 17:41:16.028648: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
Epoch 1/5
7680/7698 [============================>.] - ETA: 0s - loss: 0.0628 - categorical_accuracy: 0.9814Epoch 00000: loss improved from inf to 0.06272, saving model to coins-weights-i7698/7698 [==============================] - 13s - loss: 0.0627 - categorical_accuracy: 0.9814
Epoch 2/5
7680/7698 [============================>.] - ETA: 0s - loss: 0.0289 - categorical_accuracy: 0.9922Epoch 00001: loss improved from 0.06272 to 0.02897, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0290 - categorical_accuracy: 0.9921
Epoch 3/5
7680/7698 [============================>.] - ETA: 0s - loss: 0.0276 - categorical_accuracy: 0.9910Epoch 00002: loss improved from 0.02897 to 0.02760, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0276 - categorical_accuracy: 0.9910
Epoch 4/5
7698/7698 [==============================] - 12s - loss: 0.0321 - categorical_accuracy: 0.9896    Epoch 00003: loss did not improve
Epoch 5/5
7698/7698 [==============================] - 12s - loss: 0.0444 - categorical_accuracy: 0.9870    Epoch 00004: loss did not improve
1925/1925 [==============================] - 1s
Accuracy: 95.58%
(NN) ubuntu@ip-172-31-34-77:~$ python3 CoinRecognition4.py
Using TensorFlow backend.
Generating classification ready images
Creating dataset for classification
(9623, 100, 100, 3)
Done!

_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_1 (Conv2D)            (None, 98, 98, 64)        1792
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 49, 49, 64)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 49, 49, 64)        36928
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 24, 24, 64)        0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 24, 24, 64)        36928
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 12, 12, 64)        0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 12, 12, 64)        36928
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_5 (Conv2D)            (None, 6, 6, 64)          36928
_________________________________________________________________
max_pooling2d_5 (MaxPooling2 (None, 3, 3, 64)          0
_________________________________________________________________
conv2d_6 (Conv2D)            (None, 1, 1, 256)         147712
_________________________________________________________________
flatten_1 (Flatten)          (None, 256)               0
_________________________________________________________________
dense_1 (Dense)              (None, 128)               32896
_________________________________________________________________
dropout_1 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_2 (Dense)              (None, 128)               16512
_________________________________________________________________
dropout_2 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_3 (Dense)              (None, 5)                 645
=================================================================
Total params: 347,269.0
Trainable params: 347,269.0
Non-trainable params: 0.0
_________________________________________________________________
2017-05-20 17:43:16.318684: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:43:16.318736: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:43:16.318743: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:43:16.318754: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:43:16.318777: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
2017-05-20 17:43:19.383383: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2017-05-20 17:43:19.383888: I tensorflow/core/common_runtime/gpu/gpu_device.cc:887] Found device 0 with properties:
name: Tesla K80
major: 3 minor: 7 memoryClockRate (GHz) 0.8235
pciBusID 0000:00:1e.0
Total memory: 11.17GiB
Free memory: 11.11GiB
2017-05-20 17:43:19.383916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:908] DMA: 0
2017-05-20 17:43:19.383933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:918] 0:   Y
2017-05-20 17:43:19.383954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:977] Creating TensorFlow device (/gpu:0) -> (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0)
Epoch 1/3
7680/7698 [============================>.] - ETA: 0s - loss: 0.0852 - categorical_accuracy: 0.9759Epoch 00000: loss improved from inf to 0.08504, saving model to coins-weights-i7698/7698 [==============================] - 14s - loss: 0.0850 - categorical_accuracy: 0.9760
Epoch 2/3
7680/7698 [============================>.] - ETA: 0s - loss: 0.0202 - categorical_accuracy: 0.9947Epoch 00001: loss improved from 0.08504 to 0.02014, saving model to coins-weigh7698/7698 [==============================] - 12s - loss: 0.0201 - categorical_accuracy: 0.9947
Epoch 3/3
7698/7698 [==============================] - 12s - loss: 0.0616 - categorical_accuracy: 0.9809    Epoch 00002: loss did not improve
1925/1925 [==============================] - 1s
Accuracy: 99.06%
_________________________________________________________________
Layer (type)                 Output Shape              Param #
=================================================================
conv2d_7 (Conv2D)            (None, 98, 98, 64)        1792
_________________________________________________________________
max_pooling2d_6 (MaxPooling2 (None, 49, 49, 64)        0
_________________________________________________________________
conv2d_8 (Conv2D)            (None, 49, 49, 64)        36928
_________________________________________________________________
max_pooling2d_7 (MaxPooling2 (None, 24, 24, 64)        0
_________________________________________________________________
conv2d_9 (Conv2D)            (None, 24, 24, 64)        36928
_________________________________________________________________
max_pooling2d_8 (MaxPooling2 (None, 12, 12, 64)        0
_________________________________________________________________
conv2d_10 (Conv2D)           (None, 12, 12, 64)        36928
_________________________________________________________________
max_pooling2d_9 (MaxPooling2 (None, 6, 6, 64)          0
_________________________________________________________________
conv2d_11 (Conv2D)           (None, 6, 6, 64)          36928
_________________________________________________________________
max_pooling2d_10 (MaxPooling (None, 3, 3, 64)          0
_________________________________________________________________
conv2d_12 (Conv2D)           (None, 1, 1, 256)         147712
_________________________________________________________________
flatten_2 (Flatten)          (None, 256)               0
_________________________________________________________________
dense_4 (Dense)              (None, 128)               32896
_________________________________________________________________
dropout_3 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_5 (Dense)              (None, 128)               16512
_________________________________________________________________
dropout_4 (Dropout)          (None, 128)               0
_________________________________________________________________
dense_6 (Dense)              (None, 5)                 645
=================================================================
Total params: 347,269.0
Trainable params: 347,269.0
Non-trainable params: 0.0
_________________________________________________________________

Accuracy = 77.0%
Accuracy = 154/200
Progress = 200/6028

Accuracy = 78.5%
Accuracy = 314/400
Progress = 400/6028

Accuracy = 77.83333333333333%
Accuracy = 467/600
Progress = 600/6028

Accuracy = 77.875%
Accuracy = 623/800
Progress = 800/6028

Accuracy = 78.4%
Accuracy = 784/1000
Progress = 1000/6028

Accuracy = 78.41666666666667%
Accuracy = 941/1200
Progress = 1200/6028

Accuracy = 78.57142857142857%
Accuracy = 1100/1400
Progress = 1400/6028

Accuracy = 78.375%
Accuracy = 1254/1600
Progress = 1600/6028

Accuracy = 78.11111111111111%
Accuracy = 1406/1800
Progress = 1800/6028

Accuracy = 78.15%
Accuracy = 1563/2000
Progress = 2000/6028

Accuracy = 78.5%
Accuracy = 1727/2200
Progress = 2200/6028

Accuracy = 77.95833333333333%
Accuracy = 1871/2400
Progress = 2400/6028

Accuracy = 78.0%
Accuracy = 2028/2600
Progress = 2600/6028

Accuracy = 77.71428571428571%
Accuracy = 2176/2800
Progress = 2800/6028

Accuracy = 77.93333333333334%
Accuracy = 2338/3000
Progress = 3000/6028

Accuracy = 77.375%
Accuracy = 2476/3200
Progress = 3200/6028

Accuracy = 77.38235294117646%
Accuracy = 2631/3400
Progress = 3400/6028

Accuracy = 77.19444444444444%
Accuracy = 2779/3600
Progress = 3600/6028

Accuracy = 77.3157894736842%
Accuracy = 2938/3800
Progress = 3800/6028

Accuracy = 77.15%
Accuracy = 3086/4000
Progress = 4000/6028

Accuracy = 77.21428571428571%
Accuracy = 3243/4200
Progress = 4200/6028

Accuracy = 77.43181818181819%
Accuracy = 3407/4400
Progress = 4400/6028

Accuracy = 77.41304347826087%
Accuracy = 3561/4600
Progress = 4600/6028

Accuracy = 77.22916666666667%
Accuracy = 3707/4800
Progress = 4800/6028

Accuracy = 77.3%
Accuracy = 3865/5000
Progress = 5000/6028

Accuracy = 77.13461538461539%
Accuracy = 4011/5200
Progress = 5200/6028

Accuracy = 77.07407407407408%
Accuracy = 4162/5400
Progress = 5400/6028

Accuracy = 76.96428571428571%
Accuracy = 4310/5600
Progress = 5600/6028

Accuracy = 76.98275862068965%
Accuracy = 4465/5800
Progress = 5800/6028

Accuracy = 77.13333333333334%
Accuracy = 4628/6000
Progress = 6000/6028

Accuracy = 77.14001327140014%
Accuracy = 4650/6028
Progress = 6028/6028
